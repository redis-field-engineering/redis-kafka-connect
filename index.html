<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Asciidoctor 2.0.10">
<meta name="author" content="Julien Ruaux">
<title>Redis Kafka Connector</title>
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700">
<link rel="stylesheet" href="./asciidoctor.css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
<style>
.hidden {
    display: none;
}

.switch {
    border-width: 1px 1px 0 1px;
    border-style: solid;
    border-color: #7a2518;
    display: inline-block;
}

.switch--item {
    padding: 10px;
    background-color: #ffffff;
    color: #7a2518;
    display: inline-block;
    cursor: pointer;
}

.switch--item.selected {
    background-color: #7a2519;
    color: #ffffff;
}

</style>
<script src="https://cdnjs.cloudflare.com/ajax/libs/zepto/1.2.0/zepto.min.js"></script>
<script type="text/javascript">
function addBlockSwitches() {
    $('.primary').each(function() {
        primary = $(this);
        createSwitchItem(primary, createBlockSwitch(primary)).item.addClass("selected");
        primary.children('.title').remove();
    });
    $('.secondary').each(function(idx, node) {
        secondary = $(node);
        primary = findPrimary(secondary);
        switchItem = createSwitchItem(secondary, primary.children('.switch'));
        switchItem.content.addClass('hidden');
        findPrimary(secondary).append(switchItem.content);
        secondary.remove();
    });
}

function createBlockSwitch(primary) {
    blockSwitch = $('<div class="switch"></div>');
    primary.prepend(blockSwitch);
    return blockSwitch;
}

function findPrimary(secondary) {
    candidate = secondary.prev();
    while (!candidate.is('.primary')) {
        candidate = candidate.prev();
    }
    return candidate;
}

function createSwitchItem(block, blockSwitch) {
    blockName = block.children('.title').text();
    content = block.children('.content').first().append(block.next('.colist'));
    item = $('<div class="switch--item">' + blockName + '</div>');
    item.on('click', '', content, function(e) {
        $(this).addClass('selected');
        $(this).siblings().removeClass('selected');
        e.data.siblings('.content').addClass('hidden');
        e.data.removeClass('hidden');
    });
    blockSwitch.append(item);
    return {'item': item, 'content': content};
}

$(addBlockSwitches);

</script>

</head>
<body class="book toc2 toc-left">
<div id="header">
<h1>Redis Kafka Connector</h1>
<div class="details">
<span id="author" class="author">Julien Ruaux</span><br>
<span id="revnumber">version 1.1.0</span>
</div>
<div id="toc" class="toc2">
<div id="toctitle">Table of Contents</div>
<ul class="sectlevel1">
<li><a href="#_overview">1. Overview</a></li>
<li><a href="#_quickstart">2. Quick Start</a>
<ul class="sectlevel2">
<li><a href="#_requirements">2.1. Requirements</a></li>
<li><a href="#_start_the_sandbox">2.2. Start the Sandbox</a></li>
<li><a href="#_add_connectors">2.3. Add Connectors</a></li>
<li><a href="#_custom_connector">2.4. Custom Connector</a></li>
<li><a href="#_docker">2.5. Docker Example</a></li>
</ul>
</li>
<li><a href="#_install">3. Install</a>
<ul class="sectlevel2">
<li><a href="#_download">3.1. Download</a></li>
<li><a href="#_confluent_hub">3.2. Confluent Hub</a></li>
<li><a href="#_manually">3.3. Manually</a></li>
</ul>
</li>
<li><a href="#_sink">4. Sink Connector</a>
<ul class="sectlevel2">
<li><a href="#_class_name">4.1. Class Name</a></li>
<li><a href="#_sink_delivery">4.2. At least once delivery</a></li>
<li><a href="#_sink_tasks">4.3. Tasks</a></li>
<li><a href="#_sink_redis_client">4.4. Redis Client</a></li>
<li><a href="#_sink_redis_command">4.5. Redis Data Structures</a></li>
<li><a href="#_sink_data_formats">4.6. Data Formats</a></li>
<li><a href="#_sink_ttl">4.7. TTL (Time To Live)</a></li>
<li><a href="#_sink_config">4.8. Configuration</a></li>
</ul>
</li>
<li><a href="#_source_stream">5. Stream Source Connector</a>
<ul class="sectlevel2">
<li><a href="#_source_stream_class">5.1. Class Name</a></li>
<li><a href="#_source_stream_delivery">5.2. Delivery Guarantees</a></li>
<li><a href="#_source_stream_tasks">5.3. Tasks</a></li>
<li><a href="#_source_stream_redis_client">5.4. Redis Client</a></li>
<li><a href="#_source_stream_schema">5.5. Message Schema</a></li>
</ul>
</li>
<li><a href="#_source_keys">6. Keys Source Connector</a>
<ul class="sectlevel2">
<li><a href="#_source_keys_class">6.1. Class Name</a></li>
<li><a href="#_source_keys_delivery">6.2. Delivery Guarantees</a></li>
<li><a href="#_source_keys_tasks">6.3. Tasks</a></li>
<li><a href="#_source_keys_redis_client">6.4. Redis Client</a></li>
<li><a href="#_source_keys_config">6.5. Configuration</a></li>
</ul>
</li>
<li><a href="#_resources">7. Resources</a>
<ul class="sectlevel2">
<li><a href="#_kafka">7.1. Kafka</a></li>
<li><a href="#_kafka_connect">7.2. Kafka Connect</a></li>
<li><a href="#_redis">7.3. Redis</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div id="content">
<div class="sect1">
<h2 id="_overview"><a class="anchor" href="#_overview"></a>1. Overview</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Redis Kafka Connector is a Confluent-verified connector that stores data from Kafka topics into Redis and pushes data from Redis into Kafka topics.</p>
</div>
<div class="paragraph">
<p><span class="image"><img src="images/redis-kafka-connector.svg" alt="redis kafka connector"></span></p>
</div>
<div class="paragraph">
<p>This guide provides documentation and usage information across the following topics:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><a href="#_quickstart">Quick Start</a></p>
</li>
<li>
<p><a href="#_docker">Docker Example</a></p>
</li>
<li>
<p><a href="#_install">Install</a></p>
</li>
<li>
<p><a href="#_sink">Sink Connector</a></p>
</li>
<li>
<p><a href="#_source_stream">Stream Source Connector</a></p>
</li>
<li>
<p><a href="#_source_keys">Keys Source Connector</a></p>
</li>
<li>
<p><a href="#_resources">Resources</a></p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_quickstart"><a class="anchor" href="#_quickstart"></a>2. Quick Start</h2>
<div class="sectionbody">
<div class="paragraph">
<p>This section shows how to configure the Redis Kafka Connector to import/export data between Redis and Apache Kafka and provides a hands-on look at the functionality of the source and sink connectors.</p>
</div>
<div class="sect2">
<h3 id="_requirements"><a class="anchor" href="#_requirements"></a>2.1. Requirements</h3>
<div class="paragraph">
<p>Download and install the following software:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><a href="https://docs.docker.com/get-docker/">Docker</a></p>
</li>
<li>
<p><a href="https://git-scm.com/book/en/v2/Getting-Started-Installing-Git">Git</a></p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_start_the_sandbox"><a class="anchor" href="#_start_the_sandbox"></a>2.2. Start the Sandbox</h3>
<div class="paragraph">
<p>The sandbox starts the following Docker services:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Redis Stack</p>
</li>
<li>
<p>Apache Kafka</p>
</li>
<li>
<p>Kafka Connect with the Redis Kafka Connector installed</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>To start the sandbox run the following command:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="console">docker compose up</code></pre>
</div>
</div>
<div class="paragraph">
<p>After Docker downloads and starts the services you should see the following output:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="console">[+] Running 8/0
 ✔ Container redis            Created
 ✔ Container zookeeper        Created
 ✔ Container broker           Created
 ✔ Container schema-registry  Created
 ✔ Container rest-proxy       Created
 ✔ Container connect          Created
 ✔ Container ksqldb-server    Created
 ✔ Container control-center   Created</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_add_connectors"><a class="anchor" href="#_add_connectors"></a>2.3. Add Connectors</h3>
<div class="paragraph">
<p>Now that the required services are up and running, we can add connectors to Kafka Connect to transfer data between Redis and Kafka:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Add a sink connector to transfer data from Kafka to Redis</p>
</li>
<li>
<p>Add a source connector to transfer data from Redis to Kafka</p>
</li>
</ul>
</div>
<div class="sect3">
<h4 id="_add_a_datagen"><a class="anchor" href="#_add_a_datagen"></a>2.3.1. Add a Datagen</h4>
<div class="paragraph">
<p><a href="https://github.com/confluentinc/kafka-connect-datagen/">Kafka Connect Datagen</a> is a Kafka Connect source connector for generating mock data.</p>
</div>
<div class="paragraph">
<p>Create the Datagen connector with the following command:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="console">curl -X POST -H "Content-Type: application/json" --data '
  { "name": "datagen-pageviews",
    "config": {
      "connector.class": "io.confluent.kafka.connect.datagen.DatagenConnector",
      "kafka.topic": "pageviews",
      "quickstart": "pageviews",
      "key.converter": "org.apache.kafka.connect.json.JsonConverter",
      "value.converter": "org.apache.kafka.connect.json.JsonConverter",
      "value.converter.schemas.enable": "false",
      "producer.interceptor.classes": "io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor",
      "max.interval": 200,
      "iterations": 10000000,
      "tasks.max": "1"
}}' http://localhost:8083/connectors -w "\n"</code></pre>
</div>
</div>
<div class="paragraph">
<p>This automatically creates the Kafka topic <code>pageviews</code> and produces data with a schema configuration from <a href="https://github.com/confluentinc/kafka-connect-datagen/blob/master/src/main/resources/pageviews_schema.avro">pageviews_schema.avro</a></p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Why do I see the message 'Failed to connect'?</p>
</div>
<div class="paragraph">
<p>It takes up to three minutes for the Kafka Connect REST API to start.
If you receive the following error, wait three minutes and run the preceding command again.</p>
</div>
<div class="paragraph">
<p><code>curl: (7) Failed to connect to connect port 8083: Connection refused</code></p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>To confirm that you added the Datagen connector, run the following command:</p>
</div>
<div class="paragraph">
<p><code>curl -X GET <a href="http://localhost:8083/connectors" class="bare">http://localhost:8083/connectors</a></code></p>
</div>
</div>
<div class="sect3">
<h4 id="_add_a_sink_connector"><a class="anchor" href="#_add_a_sink_connector"></a>2.3.2. Add a Sink Connector</h4>
<div class="paragraph">
<p>The command below adds a Redis Kafka Connector sink connector configured with these properties:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>The class Kafka Connect uses to instantiate the connector</p>
</li>
<li>
<p>The Kafka topic from which the connector reads data</p>
</li>
<li>
<p>The connection URI of the Redis database to which the connector writes data</p>
</li>
<li>
<p>The Redis command to use for writing data (<code>JSONSET</code>)</p>
</li>
<li>
<p>Key and value converters to correctly handle incoming <code>pageviews</code> data</p>
</li>
<li>
<p>A <a href="https://docs.confluent.io/platform/current/connect/transforms/overview.html">Single Message Transforms</a> to extract a key from <code>pageviews</code> messages.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="console">curl -X POST -H "Content-Type: application/json" --data '
  {"name": "redis-sink-json",
   "config": {
     "connector.class":"com.redis.kafka.connect.RedisSinkConnector",
     "tasks.max":"1",
     "topics":"pageviews",
     "redis.uri":"redis://redis:6379",
     "redis.type":"JSON",
     "key.converter": "org.apache.kafka.connect.json.JsonConverter",
     "value.converter": "org.apache.kafka.connect.storage.StringConverter",
     "value.converter.schemas.enable": "false",
     "transforms": "Cast",
     "transforms.Cast.type": "org.apache.kafka.connect.transforms.Cast$Key",
     "transforms.Cast.spec": "string"
}}' http://localhost:8083/connectors -w "\n"</code></pre>
</div>
</div>
<div class="paragraph">
<p>You can check that Kafka messages are being written to Redis with this command:</p>
</div>
<div class="paragraph">
<p><code>docker compose exec redis /opt/redis-stack/bin/redis-cli "keys" "*"</code></p>
</div>
<div class="paragraph">
<p>You should see the following output:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="console">  1) "pageviews:6021"
  2) "pageviews:211"
  3) "pageviews:281"
  ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>To retrieve the contents of a specific key use this command:</p>
</div>
<div class="paragraph">
<p><code>docker compose exec redis /opt/redis-stack/bin/redis-cli "JSON.GET" "pageviews:1451"</code></p>
</div>
<div class="paragraph">
<p>&#8658; <code>"{\"viewtime\":1451,\"userid\":\"User_6\",\"pageid\":\"Page_35\"}"</code></p>
</div>
</div>
<div class="sect3">
<h4 id="_add_a_source_connector"><a class="anchor" href="#_add_a_source_connector"></a>2.3.3. Add a Source Connector</h4>
<div class="paragraph">
<p>The following command adds a source connector configured with these properties:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>The class Kafka Connect uses to instantiate the connector</p>
</li>
<li>
<p>The connection URI of the Redis database the connector connects to</p>
</li>
<li>
<p>The name of the Redis stream from which the connector reads messages</p>
</li>
<li>
<p>The Kafka topic to which the connector writes data</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="console">curl -X POST -H "Content-Type: application/json" --data '
{ "name": "redis-source",
  "config": {
    "tasks.max":"1",
    "connector.class":"com.redis.kafka.connect.RedisStreamSourceConnector",
    "redis.uri":"redis://redis:6379",
    "redis.stream.name":"mystream",
    "topic": "mystream"
  }
}' http://localhost:8083/connectors -w "\n"</code></pre>
</div>
</div>
<div class="paragraph">
<p>Now add a message to the <code>mystream</code> Redis stream:</p>
</div>
<div class="paragraph">
<p><code>docker compose exec redis /opt/redis-stack/bin/redis-cli "xadd" "mystream" "*" "field1" "value11" "field2" "value21"</code></p>
</div>
<div class="paragraph">
<p>Examine the topics in the Kafka UI: <a href="http://localhost:9021" class="bare">http://localhost:9021</a> or <a href="http://localhost:8000/" class="bare">http://localhost:8000/</a>.
The <code>mystream</code> topic should have the previously sent stream message.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_custom_connector"><a class="anchor" href="#_custom_connector"></a>2.4. Custom Connector</h3>
<div class="paragraph">
<p>This section describes configuration aspects that are specific to using Redis Kafka Connector as a <a href="https://docs.confluent.io/cloud/current/connectors/bring-your-connector/custom-connector-qs.html">Custom Connector</a> in Confluent Cloud.</p>
</div>
<div class="sect3">
<h4 id="_egress_endpoints"><a class="anchor" href="#_egress_endpoints"></a>2.4.1. Egress Endpoints</h4>
<div class="paragraph">
<p>It is required to specify <a href="https://docs.confluent.io/cloud/current/connectors/bring-your-connector/custom-connector-qs.html#cc-byoc-endpoints">egress endpoints</a> in order for the connector to reach the Redis database.</p>
</div>
</div>
<div class="sect3">
<h4 id="_sensitive_properties"><a class="anchor" href="#_sensitive_properties"></a>2.4.2. Sensitive Properties</h4>
<div class="paragraph">
<p>The following are <a href="https://docs.confluent.io/cloud/current/connectors/bring-your-connector/custom-connector-qs.html#sensitive">sensitive properties</a> that must be marked as such in Confluent Cloud UI.</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>redis.uri</code>: URI of the Redis database to connect to, e.g. <code>redis://redis-12000.redis.com:12000</code></p>
</li>
<li>
<p><code>redis.username</code>: Username to use to connect to Redis</p>
</li>
<li>
<p><code>redis.password</code>: Password to use to connect to Redis</p>
</li>
<li>
<p><code>redis.key.password</code>: Password of the private key file</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_docker"><a class="anchor" href="#_docker"></a>2.5. Docker Example</h3>
<div class="paragraph">
<p>The project <a href="https://github.com/redis-field-engineering/redis-kafka-connect.git">repository</a> contains a script that runs all the steps shown in the <a href="#_quickstart">Quick Start</a>.</p>
</div>
<div class="paragraph">
<p>Clone the <a href="https://github.com/redis-field-engineering/redis-kafka-connect.git">redis-kafka-connect</a> repository and execute <code>run.sh</code> in <code>docker</code> directory:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="console">git clone https://github.com/redis-field-engineering/redis-kafka-connect.git
cd redis-kafka-connect
./run.sh</code></pre>
</div>
</div>
<div class="paragraph">
<p>This will:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Run <code>docker compose up</code></p>
</li>
<li>
<p>Wait for Redis, Kafka, and Kafka Connect to be ready</p>
</li>
<li>
<p>Register the Confluent Datagen Connector</p>
</li>
<li>
<p>Register the Redis Kafka Sink Connector</p>
</li>
<li>
<p>Register the Redis Kafka Source Connector</p>
</li>
<li>
<p>Publish some events to Kafka via the Datagen connector</p>
</li>
<li>
<p>Write the events to Redis</p>
</li>
<li>
<p>Send messages to a Redis stream</p>
</li>
<li>
<p>Write the Redis stream messages back into Kafka</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Once running, examine the topics in the Kafka <a href="http://localhost:9021/">Control Center</a>:</p>
</div>
<div class="paragraph">
<p>The <code>pageviews</code> topic should contain the 10 simple documents added, each similar to:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="json">{
  "viewtime": {
    "$numberLong": "81"
  },
  "pageid": "Page_1",
  "userid": "User_8"
}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>The <code>pageviews</code> stream should contain the 10 change events.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Examine the stream in Redis:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="console">docker compose exec redis /usr/local/bin/redis-cli
xread COUNT 10 STREAMS pageviews 0</code></pre>
</div>
</div>
<div class="paragraph">
<p>Messages added to the <code>mystream</code> stream will show up in the <code>mystream</code> topic.</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_install"><a class="anchor" href="#_install"></a>3. Install</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Select one of the methods below to install Redis Kafka Connector.</p>
</div>
<div class="sect2">
<h3 id="_download"><a class="anchor" href="#_download"></a>3.1. Download</h3>
<div class="paragraph">
<p>Download the latest release archive: <a href="https://github.com/{github-owner}/{github-repo}/releases">Releases</a>.</p>
</div>
</div>
<div class="sect2">
<h3 id="_confluent_hub"><a class="anchor" href="#_confluent_hub"></a>3.2. Confluent Hub</h3>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Install the <a href="https://docs.confluent.io/current/connect/managing/confluent-hub/client.html">Confluent Hub Client</a></p>
</li>
<li>
<p>Install the redis-kafka-connect using the Confluent Hub Client</p>
</li>
</ol>
</div>
</div>
<div class="sect2">
<h3 id="_manually"><a class="anchor" href="#_manually"></a>3.3. Manually</h3>
<div class="paragraph">
<p>Follow the instructions in <a href="https://docs.confluent.io/home/connect/community.html#manually-installing-community-connectors/">Manually Installing Community Connectors</a>.</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_sink"><a class="anchor" href="#_sink"></a>4. Sink Connector</h2>
<div class="sectionbody">
<div class="paragraph">
<p>The Sink Connector consumes records from a Kafka topic and writes the data to Redis.</p>
</div>
<div class="sect2">
<h3 id="_class_name"><a class="anchor" href="#_class_name"></a>4.1. Class Name</h3>
<div class="paragraph">
<p>The sink connector class name is <code>com.redis.kafka.connect.RedisSinkConnector</code>.</p>
</div>
<div class="paragraph">
<p>The corresponding configuration property would be:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="properties">connector.class = com.redis.kafka.connect.RedisSinkConnector</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_sink_delivery"><a class="anchor" href="#_sink_delivery"></a>4.2. At least once delivery</h3>
<div class="paragraph">
<p>The Sink Connector guarantees that records from the Kafka topic are delivered at least once.</p>
</div>
</div>
<div class="sect2">
<h3 id="_sink_tasks"><a class="anchor" href="#_sink_tasks"></a>4.3. Tasks</h3>
<div class="paragraph">
<p>The Sink Connector supports running one or more tasks.
You can specify the number of tasks with the <code>tasks.max</code> configuration property.</p>
</div>
</div>
<div class="sect2">
<h3 id="_sink_redis_client"><a class="anchor" href="#_sink_redis_client"></a>4.4. Redis Client</h3>
<div class="paragraph">
<p>This section provides information on Redis client configuration.</p>
</div>
<div class="sect3">
<h4 id="_redis_uri"><a class="anchor" href="#_redis_uri"></a>4.4.1. Redis URI</h4>
<div class="paragraph">
<p>Specify the Redis URI in the <code>redis.uri</code> property, for example:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="properties">redis.uri = redis://redis-12000.redis.com:12000</code></pre>
</div>
</div>
<div class="paragraph">
<p>For complete Redis URI syntax see <a href="https://github.com/lettuce-io/lettuce-core/wiki/Redis-URI-and-connection-details#uri-syntax">Redis URI Syntax</a>.</p>
</div>
<div class="paragraph">
<p>TLS connection URIs start with <code>rediss://</code>.</p>
</div>
</div>
<div class="sect3">
<h4 id="_certificate_verification"><a class="anchor" href="#_certificate_verification"></a>4.4.2. Certificate Verification</h4>
<div class="paragraph">
<p>To disable certificate verification for TLS connections use the following property:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="properties">redis.insecure = true</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_credentials"><a class="anchor" href="#_credentials"></a>4.4.3. Credentials</h4>
<div class="paragraph">
<p>Username and password can be specified in the URI or separately with the following properties:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="properties">redis.username = user1
redis.password = pass</code></pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_sink_redis_command"><a class="anchor" href="#_sink_redis_command"></a>4.5. Redis Data Structures</h3>
<div class="paragraph">
<p>The Sink Connector supports the following Redis data-structure types as targets:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><a href="#_sink_string">string</a></p>
</li>
<li>
<p><a href="#_sink_json">JSON</a></p>
</li>
<li>
<p><a href="#_sink_hash">Hash</a></p>
</li>
<li>
<p><a href="#_sink_stream">stream</a></p>
</li>
<li>
<p><a href="#_sink_list">list</a></p>
</li>
<li>
<p><a href="#_sink_set">set</a></p>
</li>
<li>
<p><a href="#_sink_zset">sorted set</a></p>
</li>
<li>
<p><a href="#_sink_timeseries">time series</a></p>
</li>
</ul>
</div>
<div class="sect3">
<h4 id="_redis_keys"><a class="anchor" href="#_redis_keys"></a>4.5.1. Redis Keys</h4>
<div class="paragraph">
<p>Redis keys are generated using the <code>redis.keyspace</code> configuration property which may contain <code>${topic}</code> (default) as a placeholder for the originating topic name.</p>
</div>
<div class="paragraph">
<p>For <code>string</code>, <code>json</code>, and <code>hash</code> data structures, the Kafka message key will be appended to the keyspace.
For example, with <code>redis.type = string</code>, <code>redis.keyspace = ${topic}</code>, a message coming from topic <code>orders</code> with a key of <code>123</code> will translate into a Redis key of <code>orders:123</code>.</p>
</div>
<div class="paragraph">
<p>Leave the keyspace empty ( <code>redis.keyspace =</code> ) if you don&#8217;t want any key prefix and just use the message key.</p>
</div>
<div class="paragraph">
<p>For <code>stream</code>, <code>list</code>, <code>set</code>, <code>zset</code>, and <code>timeseries</code> the Redis key is just the keyspace.
For example with <code>redis.keyspace = set:${topic}</code> and topic <code>orders</code> the Redis key is <code>set:orders</code>.</p>
</div>
</div>
<div class="sect3">
<h4 id="_sink_string"><a class="anchor" href="#_sink_string"></a>4.5.2. String</h4>
<div class="paragraph">
<p>Use the following properties to write Kafka records as Redis strings:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="properties">redis.type      = STRING
key.converter   = &lt;string or bytes&gt; <i class="conum" data-value="1"></i><b>(1)</b>
value.converter = &lt;string or bytes&gt; <i class="conum" data-value="2"></i><b>(2)</b></code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td><a href="#_sink_key_string">String</a> or <a href="#_sink_key_bytes">bytes</a></td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td><a href="#_sink_value_string">String</a> or <a href="#_sink_value_bytes">bytes</a>.
If value is null the key is deleted.</td>
</tr>
</table>
</div>
</div>
<div class="sect3">
<h4 id="_sink_json"><a class="anchor" href="#_sink_json"></a>4.5.3. JSON</h4>
<div class="paragraph">
<p>Use the following properties to write Kafka records as RedisJSON documents:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="properties">redis.type      = JSON
key.converter   = &lt;string, bytes, or Avro&gt; <i class="conum" data-value="1"></i><b>(1)</b>
value.converter = &lt;string, bytes, or Avro&gt; <i class="conum" data-value="2"></i><b>(2)</b></code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td><a href="#_sink_key_string">String</a>, <a href="#_sink_key_bytes">bytes</a>, or <a href="#_sink_value_avro">Avro</a></td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td><a href="#_sink_value_string">String</a>, <a href="#_sink_value_bytes">bytes</a>, or <a href="#_sink_value_avro">Avro</a>.
If value is null the key is deleted.</td>
</tr>
</table>
</div>
</div>
<div class="sect3">
<h4 id="_sink_hash"><a class="anchor" href="#_sink_hash"></a>4.5.4. Hash</h4>
<div class="paragraph">
<p>Use the following properties to write Kafka records as Redis hashes:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="properties">redis.type      = HASH
key.converter   = &lt;string or bytes&gt; <i class="conum" data-value="1"></i><b>(1)</b>
value.converter = &lt;Avro or JSON&gt; <i class="conum" data-value="2"></i><b>(2)</b></code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td><a href="#_sink_key_string">String</a> or <a href="#_sink_key_bytes">bytes</a></td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td><a href="#_sink_value_avro">Avro</a> or <a href="#_sink_value_json">JSON</a>.
If value is null the key is deleted.</td>
</tr>
</table>
</div>
</div>
<div class="sect3">
<h4 id="_sink_stream"><a class="anchor" href="#_sink_stream"></a>4.5.5. Stream</h4>
<div class="paragraph">
<p>Use the following properties to store Kafka records as Redis stream messages:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="properties">redis.type      = STREAM
redis.keyspace  = &lt;stream key&gt; <i class="conum" data-value="1"></i><b>(1)</b>
value.converter = &lt;Avro or JSON&gt; <i class="conum" data-value="2"></i><b>(2)</b></code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Stream key</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td><a href="#_sink_value_avro">Avro</a> or <a href="#_sink_value_json">JSON</a></td>
</tr>
</table>
</div>
</div>
<div class="sect3">
<h4 id="_sink_list"><a class="anchor" href="#_sink_list"></a>4.5.6. List</h4>
<div class="paragraph">
<p>Use the following properties to add Kafka record keys to a Redis list:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="properties">redis.type     = LIST
redis.keyspace = &lt;list key&gt; <i class="conum" data-value="2"></i><b>(2)</b>
key.converter  = &lt;string or bytes&gt; <i class="conum" data-value="3"></i><b>(3)</b></code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td><code>LPUSH</code> or <code>RPUSH</code></td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>List key</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td><a href="#_sink_key_string">String</a> or <a href="#_sink_key_bytes">bytes</a>: Kafka record keys to push to the list</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>The Kafka record value can be any format.
If a value is null then the member is removed from the list (instead of pushed to the list).</p>
</div>
</div>
<div class="sect3">
<h4 id="_sink_set"><a class="anchor" href="#_sink_set"></a>4.5.7. Set</h4>
<div class="paragraph">
<p>Use the following properties to add Kafka record keys to a Redis set:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="properties">redis.type     = SET
redis.keyspace = &lt;set key&gt; <i class="conum" data-value="1"></i><b>(1)</b>
key.converter  = &lt;string or bytes&gt; <i class="conum" data-value="2"></i><b>(2)</b></code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Set key</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td><a href="#_sink_key_string">String</a> or <a href="#_sink_key_bytes">bytes</a>: Kafka record keys to add to the set</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>The Kafka record value can be any format.
If a value is null then the member is removed from the set (instead of added to the set).</p>
</div>
</div>
<div class="sect3">
<h4 id="_sink_zset"><a class="anchor" href="#_sink_zset"></a>4.5.8. Sorted Set</h4>
<div class="paragraph">
<p>Use the following properties to add Kafka record keys to a Redis sorted set:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="properties">redis.type     = ZSET
redis.keyspace = &lt;zset key&gt; <i class="conum" data-value="1"></i><b>(1)</b>
key.converter  = &lt;string or bytes&gt; <i class="conum" data-value="2"></i><b>(2)</b></code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Sorted set key</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td><a href="#_sink_key_string">String</a> or <a href="#_sink_key_bytes">bytes</a>: Kafka record keys to add to the set</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>The Kafka record value should be <code>float64</code> and is used for the score.
If the score is null then the member is removed from the sorted set (instead of added to the sorted set).</p>
</div>
</div>
<div class="sect3">
<h4 id="_sink_timeseries"><a class="anchor" href="#_sink_timeseries"></a>4.5.9. Timeseries</h4>
<div class="paragraph">
<p>Use the following properties to write Kafka records as RedisTimeSeries samples:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="properties">redis.type     = TIMESERIES
redis.keyspace = &lt;key name&gt; <i class="conum" data-value="1"></i><b>(1)</b></code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Timeseries key</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>The Kafka record key must be an integer (e.g. <code>int64</code>) as it is used for the sample time in milliseconds.</p>
</div>
<div class="paragraph">
<p>The Kafka record value must be a number (e.g. <code>float64</code>) as it is used as the sample value.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_sink_data_formats"><a class="anchor" href="#_sink_data_formats"></a>4.6. Data Formats</h3>
<div class="paragraph">
<p>The Sink Connector supports different data formats for record keys and values depending on the target Redis data structure.</p>
</div>
<div class="sect3">
<h4 id="_sink_key"><a class="anchor" href="#_sink_key"></a>4.6.1. Kafka Record Key</h4>
<div class="paragraph">
<p>The Sink Connector expects Kafka record keys in a specific format depending on the configured target <a href="#_sink_redis_command">Redis data structure</a>:</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Target</th>
<th class="tableblock halign-left valign-top">Record Key</th>
<th class="tableblock halign-left valign-top">Assigned To</th>
</tr>
</thead>
<tbody>
<tr>
<th class="tableblock halign-left valign-top"><p class="tableblock">Stream</p></th>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">None</p></td>
</tr>
<tr>
<th class="tableblock halign-left valign-top"><p class="tableblock">Hash</p></th>
<td class="tableblock halign-left valign-top"><p class="tableblock">String</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Key</p></td>
</tr>
<tr>
<th class="tableblock halign-left valign-top"><p class="tableblock">String</p></th>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#_sink_key_string">String</a> or <a href="#_sink_key_bytes">bytes</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Key</p></td>
</tr>
<tr>
<th class="tableblock halign-left valign-top"><p class="tableblock">List</p></th>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#_sink_key_string">String</a> or <a href="#_sink_key_bytes">bytes</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Member</p></td>
</tr>
<tr>
<th class="tableblock halign-left valign-top"><p class="tableblock">Set</p></th>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#_sink_key_string">String</a> or <a href="#_sink_key_bytes">bytes</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Member</p></td>
</tr>
<tr>
<th class="tableblock halign-left valign-top"><p class="tableblock">Sorted Set</p></th>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#_sink_key_string">String</a> or <a href="#_sink_key_bytes">bytes</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Member</p></td>
</tr>
<tr>
<th class="tableblock halign-left valign-top"><p class="tableblock">JSON</p></th>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#_sink_key_string">String</a> or <a href="#_sink_key_bytes">bytes</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Key</p></td>
</tr>
<tr>
<th class="tableblock halign-left valign-top"><p class="tableblock">TimeSeries</p></th>
<td class="tableblock halign-left valign-top"><p class="tableblock">Integer</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Sample time in milliseconds</p></td>
</tr>
</tbody>
</table>
<div class="sect4">
<h5 id="_sink_key_string"><a class="anchor" href="#_sink_key_string"></a>StringConverter</h5>
<div class="paragraph">
<p>If record keys are already serialized as strings use the StringConverter:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="properties">key.converter = org.apache.kafka.connect.storage.StringConverter</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_sink_key_bytes"><a class="anchor" href="#_sink_key_bytes"></a>ByteArrayConverter</h5>
<div class="paragraph">
<p>Use the byte array converter to use the binary serialized form of the Kafka record keys:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="properties">key.converter = org.apache.kafka.connect.converters.ByteArrayConverter</code></pre>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_sink_value"><a class="anchor" href="#_sink_value"></a>4.6.2. Kafka Record Value</h4>
<div class="paragraph">
<p>Multiple data formats are supported for Kafka record values depending on the configured target <a href="#_sink_redis_command">Redis data structure</a>.
Each data structure expects a specific format.
If your data in Kafka is not in the format expected for a given data structure, consider using <a href="https://docs.confluent.io/platform/current/connect/transforms/overview.html">Single Message Transforms</a> to convert to a byte array, string, Struct, or map before it is written to Redis.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Target</th>
<th class="tableblock halign-left valign-top">Record Value</th>
<th class="tableblock halign-left valign-top">Assigned To</th>
</tr>
</thead>
<tbody>
<tr>
<th class="tableblock halign-left valign-top"><p class="tableblock">Stream</p></th>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#_sink_value_avro">Avro</a> or <a href="#_sink_value_json">JSON</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Message body</p></td>
</tr>
<tr>
<th class="tableblock halign-left valign-top"><p class="tableblock">Hash</p></th>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#_sink_value_avro">Avro</a> or <a href="#_sink_value_json">JSON</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Fields</p></td>
</tr>
<tr>
<th class="tableblock halign-left valign-top"><p class="tableblock">String</p></th>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#_sink_value_string">String</a> or <a href="#_sink_value_bytes">bytes</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Value</p></td>
</tr>
<tr>
<th class="tableblock halign-left valign-top"><p class="tableblock">List</p></th>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Removal if null</p></td>
</tr>
<tr>
<th class="tableblock halign-left valign-top"><p class="tableblock">Set</p></th>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Removal if null</p></td>
</tr>
<tr>
<th class="tableblock halign-left valign-top"><p class="tableblock">Sorted Set</p></th>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Score or removal if null</p></td>
</tr>
<tr>
<th class="tableblock halign-left valign-top"><p class="tableblock">JSON</p></th>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#_sink_value_string">String</a> or <a href="#_sink_value_bytes">bytes</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Value</p></td>
</tr>
<tr>
<th class="tableblock halign-left valign-top"><p class="tableblock">TimeSeries</p></th>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Sample value</p></td>
</tr>
</tbody>
</table>
<div class="sect4">
<h5 id="_sink_value_string"><a class="anchor" href="#_sink_value_string"></a>StringConverter</h5>
<div class="paragraph">
<p>If record values are already serialized as strings, use the StringConverter to store values in Redis as strings:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="properties">value.converter = org.apache.kafka.connect.storage.StringConverter</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_sink_value_bytes"><a class="anchor" href="#_sink_value_bytes"></a>ByteArrayConverter</h5>
<div class="paragraph">
<p>Use the byte array converter to store the binary serialized form (for example, JSON, Avro, Strings, etc.) of the Kafka record values in Redis as byte arrays:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="properties">value.converter = org.apache.kafka.connect.converters.ByteArrayConverter</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_sink_value_avro"><a class="anchor" href="#_sink_value_avro"></a>Avro</h5>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="properties">value.converter                     = io.confluent.connect.avro.AvroConverter
value.converter.schema.registry.url = http://localhost:8081</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_sink_value_json"><a class="anchor" href="#_sink_value_json"></a>JSON</h5>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="properties">value.converter                = org.apache.kafka.connect.json.JsonConverter
value.converter.schemas.enable = &lt;true|false&gt; <i class="conum" data-value="1"></i><b>(1)</b></code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Set to <code>true</code> if the JSON record structure has an attached schema</td>
</tr>
</table>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_sink_ttl"><a class="anchor" href="#_sink_ttl"></a>4.7. TTL (Time To Live)</h3>
<div class="paragraph">
<p>The Sink Connector supports setting TTL (Time To Live) for Redis keys to automatically expire data after a specified duration. TTL can be configured globally for all keys or per-message using Kafka headers.</p>
</div>
<div class="sect3">
<h4 id="_global_ttl_configuration"><a class="anchor" href="#_global_ttl_configuration"></a>4.7.1. Global TTL Configuration</h4>
<div class="paragraph">
<p>Set a global TTL for all keys using the <code>redis.key.ttl</code> configuration property:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="properties">redis.key.ttl = 3600  # TTL in seconds (1 hour)</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_per_message_ttl"><a class="anchor" href="#_per_message_ttl"></a>4.7.2. Per-Message TTL</h4>
<div class="paragraph">
<p>Include a <code>redis.key.ttl</code> header in your Kafka messages to set TTL for individual records:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="java">ProducerRecord&lt;String, String&gt; record = new ProducerRecord&lt;&gt;("topic", "key", "value");
record.headers().add("redis.key.ttl", "1800".getBytes()); // 30 minutes</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_ttl_behavior"><a class="anchor" href="#_ttl_behavior"></a>4.7.3. TTL Behavior</h4>
<div class="ulist">
<ul>
<li>
<p>TTL is applied using the Redis <code>EXPIRE</code> command after data is written</p>
</li>
<li>
<p>Per-message TTL headers take precedence over global configuration</p>
</li>
<li>
<p>TTL applies to all Redis data types</p>
</li>
<li>
<p>For collection types (STREAM, LIST, SET, ZSET, TIMESERIES), TTL is applied to the collection key</p>
</li>
<li>
<p>Invalid TTL values are logged and ignored</p>
</li>
<li>
<p>TTL value of -1 (default) means no expiration</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_sink_config"><a class="anchor" href="#_sink_config"></a>4.8. Configuration</h3>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="properties">connector.class  = com.redis.kafka.connect.RedisSinkConnector
topics           = &lt;Kafka topic&gt; <i class="conum" data-value="1"></i><b>(1)</b>
redis.uri        = &lt;Redis URI&gt; <i class="conum" data-value="2"></i><b>(2)</b>
redis.type       = &lt;HASH|SET|JSON|STREAM|LIST|SET|ZSET|TIMESERIES&gt; <i class="conum" data-value="3"></i><b>(3)</b>
redis.key.ttl    = &lt;TTL in seconds&gt; <i class="conum" data-value="4"></i><b>(4)</b>
key.converter    = &lt;Key converter&gt; <i class="conum" data-value="5"></i><b>(5)</b>
value.converter  = &lt;Value converter&gt; <i class="conum" data-value="6"></i><b>(6)</b></code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Kafka topics to read messsages from.</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td><a href="#_sink_redis_client">Redis URI</a>.</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td><a href="#_sink_redis_command">Redis command</a>.</td>
</tr>
<tr>
<td><i class="conum" data-value="4"></i><b>4</b></td>
<td><a href="#_sink_ttl">TTL in seconds</a> (optional, default: -1 for no expiration).</td>
</tr>
<tr>
<td><i class="conum" data-value="5"></i><b>5</b></td>
<td><a href="#_sink_key">Key converter</a>.</td>
</tr>
<tr>
<td><i class="conum" data-value="6"></i><b>6</b></td>
<td><a href="#_sink_value">Value converter</a>.</td>
</tr>
</table>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_source_stream"><a class="anchor" href="#_source_stream"></a>5. Stream Source Connector</h2>
<div class="sectionbody">
<div class="paragraph">
<p>The Stream Source Connector reads from a Redis stream and publishes messages to a Kafka topic.</p>
</div>
<div class="sect2">
<h3 id="_source_stream_class"><a class="anchor" href="#_source_stream_class"></a>5.1. Class Name</h3>
<div class="paragraph">
<p>The Stream Source Connector class name is <code>com.redis.kafka.connect.RedisStreamSourceConnector</code>.</p>
</div>
<div class="paragraph">
<p>The corresponding configuration property would be:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="properties">connector.class = com.redis.kafka.connect.RedisStreamSourceConnector</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_source_stream_delivery"><a class="anchor" href="#_source_stream_delivery"></a>5.2. Delivery Guarantees</h3>
<div class="paragraph">
<p>The Stream Source Connector can be configured to ack stream messages either automatically (at-most-once delivery) or explicitly (at-least-once delivery).
The default is at-least-once delivery.</p>
</div>
<div class="sect3">
<h4 id="_at_least_once"><a class="anchor" href="#_at_least_once"></a>5.2.1. At-Least-Once</h4>
<div class="paragraph">
<p>In this mode, each stream message is acknowledged after it has been written to the corresponding topic.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="properties">redis.stream.delivery = at-least-once</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_at_most_once"><a class="anchor" href="#_at_most_once"></a>5.2.2. At-Most-Once</h4>
<div class="paragraph">
<p>In this mode, stream messages are acknowledged as soon as they are read.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="properties">redis.stream.delivery = at-most-once</code></pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_source_stream_tasks"><a class="anchor" href="#_source_stream_tasks"></a>5.3. Tasks</h3>
<div class="paragraph">
<p>Reading from the stream is done through a consumer group so that multiple instances of the connector configured via the <code>tasks.max</code> can consume messages in a round-robin fashion.</p>
</div>
</div>
<div class="sect2">
<h3 id="_source_stream_redis_client"><a class="anchor" href="#_source_stream_redis_client"></a>5.4. Redis Client</h3>
<div class="paragraph">
<p>This section provides information on Redis client configuration.</p>
</div>
<div class="sect3">
<h4 id="_redis_uri_2"><a class="anchor" href="#_redis_uri_2"></a>5.4.1. Redis URI</h4>
<div class="paragraph">
<p>Specify the Redis URI in the <code>redis.uri</code> property, for example:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="properties">redis.uri = redis://redis-12000.redis.com:12000</code></pre>
</div>
</div>
<div class="paragraph">
<p>For complete Redis URI syntax see <a href="https://github.com/lettuce-io/lettuce-core/wiki/Redis-URI-and-connection-details#uri-syntax">Redis URI Syntax</a>.</p>
</div>
<div class="paragraph">
<p>TLS connection URIs start with <code>rediss://</code>.</p>
</div>
</div>
<div class="sect3">
<h4 id="_certificate_verification_2"><a class="anchor" href="#_certificate_verification_2"></a>5.4.2. Certificate Verification</h4>
<div class="paragraph">
<p>To disable certificate verification for TLS connections use the following property:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="properties">redis.insecure = true</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_credentials_2"><a class="anchor" href="#_credentials_2"></a>5.4.3. Credentials</h4>
<div class="paragraph">
<p>Username and password can be specified in the URI or separately with the following properties:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="properties">redis.username = user1
redis.password = pass</code></pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_source_stream_schema"><a class="anchor" href="#_source_stream_schema"></a>5.5. Message Schema</h3>
<div class="sect3">
<h4 id="_key_schema"><a class="anchor" href="#_key_schema"></a>5.5.1. Key Schema</h4>
<div class="paragraph">
<p>Keys are of type String and contain the stream message id.</p>
</div>
</div>
<div class="sect3">
<h4 id="_value_schema"><a class="anchor" href="#_value_schema"></a>5.5.2. Value Schema</h4>
<div class="paragraph">
<p>The value schema defines the following fields:</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Schema</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">id</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">STRING</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Stream message ID</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">stream</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">STRING</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Stream key</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">body</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Map of STRING</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Stream message body</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_source_stream_config"><a class="anchor" href="#_source_stream_config"></a>5.5.3. Configuration</h4>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="properties">connector.class             = com.redis.kafka.connect.RedisStreamSourceConnector
redis.stream.name           = &lt;name&gt; <i class="conum" data-value="1"></i><b>(1)</b>
redis.stream.offset         = &lt;offset&gt; <i class="conum" data-value="2"></i><b>(2)</b>
redis.stream.block          = &lt;millis&gt; <i class="conum" data-value="3"></i><b>(3)</b>
redis.stream.consumer.group = &lt;group&gt; <i class="conum" data-value="4"></i><b>(4)</b>
redis.stream.consumer.name  = &lt;name&gt; <i class="conum" data-value="5"></i><b>(5)</b>
redis.stream.delivery       = &lt;mode&gt; <i class="conum" data-value="6"></i><b>(6)</b>
topic                       = &lt;name&gt; <i class="conum" data-value="7"></i><b>(7)</b></code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Name of the stream to read from.</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td><a href="https://redis.io/commands/xread#incomplete-ids">Message ID</a> to start reading from (default: <code>0-0</code>).</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>Maximum <a href="https://redis.io/commands/xread">XREAD</a> wait duration in milliseconds (default: <code>100</code>).</td>
</tr>
<tr>
<td><i class="conum" data-value="4"></i><b>4</b></td>
<td>Name of the stream consumer group (default: <code>kafka-consumer-group</code>).</td>
</tr>
<tr>
<td><i class="conum" data-value="5"></i><b>5</b></td>
<td>Name of the stream consumer (default: <code>consumer-${task}</code>).
May contain <code>${task}</code> as a placeholder for the task id.
For example, <code>foo${task}</code> and task <code>123</code> &#8658; consumer <code>foo123</code>.</td>
</tr>
<tr>
<td><i class="conum" data-value="6"></i><b>6</b></td>
<td>Delivery mode: <code>at-least-once</code>, <code>at-most-once</code> (default: <code>at-least-once</code>).</td>
</tr>
<tr>
<td><i class="conum" data-value="7"></i><b>7</b></td>
<td>Destination topic (default: <code>${stream}</code>).
May contain <code>${stream}</code> as a placeholder for the originating stream name.
For example, <code>redis_${stream}</code> and stream <code>orders</code> &#8658; topic <code>redis_orders</code>.</td>
</tr>
</table>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_source_keys"><a class="anchor" href="#_source_keys"></a>6. Keys Source Connector</h2>
<div class="sectionbody">
<div class="paragraph">
<p>The Keys Source Connector captures changes happening to keys in a Redis database and publishes keys and values to a Kafka topic.
The data structure key will be mapped to the record key, and the value will be mapped to the record value.</p>
</div>
<div class="paragraph">
<p><strong>Make sure the Redis database has keyspace notifications enabled</strong> using <code>notify-keyspace-events = KEA</code> in <code>redis.conf</code> or via <code>CONFIG SET</code>.
For more details see <a href="https://redis.io/docs/manual/keyspace-notifications">Redis Keyspace Notifications</a>.</p>
</div>
<div class="sect2">
<h3 id="_source_keys_class"><a class="anchor" href="#_source_keys_class"></a>6.1. Class Name</h3>
<div class="paragraph">
<p>The Keys Source Connector class name is <code>com.redis.kafka.connect.RedisKeysSourceConnector</code>.</p>
</div>
<div class="paragraph">
<p>The corresponding configuration property would be:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="properties">connector.class = com.redis.kafka.connect.RedisKeysSourceConnector</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_source_keys_delivery"><a class="anchor" href="#_source_keys_delivery"></a>6.2. Delivery Guarantees</h3>
<div class="paragraph">
<p>The Keys Source Connector does not guarantee data consistency because it relies on Redis keyspace notifications which have no delivery guarantees.
It is possible for some notifications to be missed, for example in case of network failures.</p>
</div>
<div class="paragraph">
<p>Also, depending on the type, size, and rate of change of data structures on the source it is possible the connector cannot keep up with the change stream.
For example if a big set is repeatedly updated the connector will need to read the whole set on each update and transfer it over to the target database.
With a big-enough set the connector could fall behind and the internal queue could fill up leading up to updates being dropped.
Some preliminary sizing using Redis statistics and <code>bigkeys</code>/<code>memkeys</code> is recommended.
If you need assistance please contact your Redis account team.</p>
</div>
</div>
<div class="sect2">
<h3 id="_source_keys_tasks"><a class="anchor" href="#_source_keys_tasks"></a>6.3. Tasks</h3>
<div class="paragraph">
<p>The Keys Source Connector should only be configured with one task as keyspace notifications are broadcast to all listeners and cannot be consumed in a round-robin fashion.</p>
</div>
</div>
<div class="sect2">
<h3 id="_source_keys_redis_client"><a class="anchor" href="#_source_keys_redis_client"></a>6.4. Redis Client</h3>
<div class="paragraph">
<p>This section provides information on Redis client configuration.</p>
</div>
<div class="sect3">
<h4 id="_redis_uri_3"><a class="anchor" href="#_redis_uri_3"></a>6.4.1. Redis URI</h4>
<div class="paragraph">
<p>Specify the Redis URI in the <code>redis.uri</code> property, for example:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="properties">redis.uri = redis://redis-12000.redis.com:12000</code></pre>
</div>
</div>
<div class="paragraph">
<p>For complete Redis URI syntax see <a href="https://github.com/lettuce-io/lettuce-core/wiki/Redis-URI-and-connection-details#uri-syntax">Redis URI Syntax</a>.</p>
</div>
<div class="paragraph">
<p>TLS connection URIs start with <code>rediss://</code>.</p>
</div>
</div>
<div class="sect3">
<h4 id="_certificate_verification_3"><a class="anchor" href="#_certificate_verification_3"></a>6.4.2. Certificate Verification</h4>
<div class="paragraph">
<p>To disable certificate verification for TLS connections use the following property:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="properties">redis.insecure = true</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_credentials_3"><a class="anchor" href="#_credentials_3"></a>6.4.3. Credentials</h4>
<div class="paragraph">
<p>Username and password can be specified in the URI or separately with the following properties:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="properties">redis.username = user1
redis.password = pass</code></pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_source_keys_config"><a class="anchor" href="#_source_keys_config"></a>6.5. Configuration</h3>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code data-lang="properties">connector.class    = com.redis.kafka.connect.RedisKeysSourceConnector
redis.keys.pattern = &lt;glob&gt; <i class="conum" data-value="1"></i><b>(1)</b>
redis.keys.timeout = &lt;millis&gt; <i class="conum" data-value="2"></i><b>(2)</b>
topic              = &lt;name&gt; <i class="conum" data-value="3"></i><b>(3)</b>
mode               = &lt;LIVE|LIVEONLY&gt; <i class="conum" data-value="4"></i><b>(4)</b></code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Key pattern to subscribe to.
This is the key portion of the pattern that will be used to listen to keyspace events.
<div class="paragraph">
<p>For example <code>foo:*</code> translates to pubsub channel <code>__keyspace@0__:foo:*</code> and will capture changes to keys <code>foo:1</code>, <code>foo:2</code>, etc.
See <a href="https://redis.io/commands/keys/">Redis KEYS</a> for pattern details.</p>
</div></td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>Idle timeout in millis.
Duration after which the connector will stop if no activity is encountered.</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>Name of the destination topic.</td>
</tr>
<tr>
<td><i class="conum" data-value="4"></i><b>4</b></td>
<td>Reading mode:
<div class="dlist">
<dl>
<dt class="hdlist1"><code>LIVE</code> (default)</dt>
<dd>
<p>initial snapshot + updates</p>
</dd>
<dt class="hdlist1"><code>LIVEONLY</code></dt>
<dd>
<p>just updates</p>
</dd>
</dl>
</div></td>
</tr>
</table>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_resources"><a class="anchor" href="#_resources"></a>7. Resources</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_kafka"><a class="anchor" href="#_kafka"></a>7.1. Kafka</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">What is Apache Kafka?</dt>
<dd>
<p><a href="https://youtu.be/06iRM1Ghr1k" class="bare">https://youtu.be/06iRM1Ghr1k</a></p>
</dd>
<dt class="hdlist1">Should You Put Several Event Types in the Same Kafka Topic?</dt>
<dd>
<p><a href="https://www.confluent.io/blog/put-several-event-types-kafka-topic/" class="bare">https://www.confluent.io/blog/put-several-event-types-kafka-topic/</a></p>
</dd>
<dt class="hdlist1">Kafka Quickstart</dt>
<dd>
<p><a href="https://kafka.apache.org/quickstart" class="bare">https://kafka.apache.org/quickstart</a></p>
</dd>
<dt class="hdlist1">Console Producer and Consumer Basics</dt>
<dd>
<p><a href="https://kafka-tutorials.confluent.io/kafka-console-consumer-producer-basics/kafka.html" class="bare">https://kafka-tutorials.confluent.io/kafka-console-consumer-producer-basics/kafka.html</a></p>
</dd>
</dl>
</div>
</div>
<div class="sect2">
<h3 id="_kafka_connect"><a class="anchor" href="#_kafka_connect"></a>7.2. Kafka Connect</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Introduction to Kafka Connectors</dt>
<dd>
<p><a href="https://www.baeldung.com/kafka-connectors-guide" class="bare">https://www.baeldung.com/kafka-connectors-guide</a></p>
</dd>
<dt class="hdlist1">Kafka Connect Documentation</dt>
<dd>
<p><a href="https://docs.confluent.io/platform/current/connect/index.html" class="bare">https://docs.confluent.io/platform/current/connect/index.html</a></p>
</dd>
</dl>
</div>
</div>
<div class="sect2">
<h3 id="_redis"><a class="anchor" href="#_redis"></a>7.3. Redis</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Redis</dt>
<dd>
<p><a href="https://redis.io/topics/introduction" class="bare">https://redis.io/topics/introduction</a></p>
</dd>
<dt class="hdlist1">Redis Streams</dt>
<dd>
<p><a href="https://redis.io/topics/streams-intro" class="bare">https://redis.io/topics/streams-intro</a></p>
</dd>
<dt class="hdlist1">Redis Enterprise Advantages</dt>
<dd>
<p><a href="https://redis.com/redis-enterprise/advantages/" class="bare">https://redis.com/redis-enterprise/advantages/</a></p>
</dd>
</dl>
</div>
</div>
</div>
</div>
</div>
<div id="footer">
<div id="footer-text">
Version 1.1.0<br>
Last updated 2025-09-03 19:49:51 UTC
</div>
</div>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prettify/r298/prettify.min.css">
<script src="https://cdnjs.cloudflare.com/ajax/libs/prettify/r298/run_prettify.min.js"></script>
</body>
</html>